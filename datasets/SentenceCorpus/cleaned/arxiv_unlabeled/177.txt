 
many ai researchers cognitive scientists argued analogy core cognition
most influential work computational modeling analogy-making structure mapping theory smt its implementation structure mapping engine sme
limitation sme requirement complex hand-coded representations
introduce latent relation mapping engine lrme combines ideas sme latent relational analysis lra order remove requirement hand-coded representations
lrme builds analogical mappings between lists words using large corpus raw text automatically discover semantic relations among words
evaluate lrme set twenty analogical mapping problems ten based scientific analogies ten based common metaphors
lrme achieves human-level performance twenty problems
compare lrme variety alternative approaches find they not able reach same level performance
 introduction 
when faced problem try recall similar problems faced past so transfer our knowledge past experience current problem
make analogy between past situation current situation use analogy transfer knowledge \shortcite{gentner83,minsky86,holyoak95,hofstadter01,hawkins04}
his survey computational modeling analogy-making french cites structure mapping theory smt \shortcite{gentner83} its implementation structure mapping engine sme most influential work modeling analogy-making
sme analogical mapping source target
source more familiar more known more concrete whereas target relatively unfamiliar unknown
analogical mapping used transfer knowledge source target
gentner argues there two kinds similarity attributional similarity relational similarity
distinction between attributes relations may understood terms predicate logic
attribute predicate one argument {large}  meaning large
relation predicate two more arguments {collides\_with}  meaning collides
structure mapping engine prefers mappings based relational similarity over mappings based attributional similarity \shortcite{falkenhainer89}
example sme able build mapping representation solar system source representation rutherford-bohr model atom target
sun mapped nucleus planets mapped electrons mass mapped charge
note mapping emphasizes relational similarity
sun nucleus very different terms their attributes: sun very large nucleus very small
likewise planets electrons little attributional similarity
other hand planets revolve around sun like electrons revolve around nucleus
mass sun attracts mass planets like charge nucleus attracts charge electrons
gentner provides evidence children rely primarily attributional similarity mapping gradually switching over relational similarity they mature
she uses terms mere appearance refer mapping based mostly attributional similarity analogy refer mapping based mostly relational similarity literal similarity refer mixture attributional relational similarity
since use analogical mappings solve problems make predictions should focus structure especially causal relations look beyond surface attributes things \shortcite{gentner83}
analogy between solar system rutherford-bohr model atom illustrates importance going beyond mere appearance underlying structures
figures show lisp representations used sme input analogy between solar system atom \shortcite{falkenhainer89}
chalmers french hofstadter criticize sme's requirement complex hand-coded representations
they argue most hard work done human who creates high-level hand-coded representations rather than sme } } gentner forbus their colleagues attempted avoid hand-coding their recent work sme
cogsketch system generate lisp representations simple sketches
gizmo system generate lisp representations qualitative physics models
learning reader system generate lisp representations natural language text \shortcite{forbus07}
systems do not require lisp input
however cogsketch user interface requires person who draws sketch identify basic components sketch hand-label them terms knowledge base derived opencyc
forbus et al note opencyc contains more than 58,000 hand-coded concepts they added further hand-coded concepts opencyc order support cogsketch
gizmo system requires user hand-code physical model using methods qualitative physics \shortcite{yan05}
learning reader uses more than 28,000 phrasal patterns were derived researchcyc \shortcite{forbus07}
evident sme still requires substantial hand-coded knowledge
work present paper effort avoid complex hand-coded representations
our approach combine ideas sme \shortcite{falkenhainer89} latent relational analysis lra \shortcite{turney06}
call resulting algorithm latent relation mapping engine lrme
represent semantic relation between two terms using vector elements derived pattern frequencies large corpus raw text
because semantic relations automatically derived corpus lrme does not require hand-coded representations relations
only needs list terms source list terms target
given two lists lrme uses corpus build representations relations among terms then constructs mapping between two lists
tables show input output lrme analogy between solar system ruther\-ford-bohr model atom
although some human effort involved constructing input lists considerably less effort than sme requires its input contrast figures table } } scientific analogies analogy between solar system rutherford-bohr model atom may seem esoteric but believe analogy-making ubiquitous our daily lives
potential practical application work task identifying semantic roles \shortcite{gildea02}
since roles relations not attributes appropriate treat semantic role labeling analogical mapping problem
example {judgement} semantic frame contains semantic roles {judge} {evaluee} {reason} {statement} frame contains roles {speaker} {addressee} {message} {topic} {medium} \shortcite{gildea02}
task identifying semantic roles automatically label sentences their roles following examples \shortcite{gildea02}: if training set labeled sentences testing set unlabeled sentences then may view task labeling testing sentences problem creating analogical mappings between training sentences sources testing sentences targets
table shows how ``she blames government failing do enough help
'' might mapped ``they blame company polluting environment
'' once mapping been found transfer knowledge form semantic role labels source target } section briefly discuss hypotheses behind design lrme
then precisely define task performed lrme specific form analogical mapping section
lrme builds latent relational analysis lra hence summarize lra section
discuss potential applications lrme section
evaluate lrme created twenty analogical mapping problems ten science analogy problems \shortcite{holyoak95} ten common metaphor problems \shortcite{lakoff80}
table one science analogy problems
our intended solution given table
validate our intended solutions gave our colleagues lists terms table asked them generate mappings between lists
section presents results experiment
across twenty problems average agreement our intended solutions table was 87 6\%
lrme algorithm outlined section along its evaluation twenty mapping problems
lrme achieves accuracy 91 5\%
difference between performance human average 87 6\% not statistically significant
section examines variety alternative approaches analogy mapping task
best approach achieves accuracy 76 8\% but approach requires hand-coded part-of-speech tags
performance significantly below lrme human performance
section discuss some questions raised results preceding sections
related work described section future work limitations considered section conclude section
